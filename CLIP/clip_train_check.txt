import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Load CSVs
clip_df = pd.read_csv("clip_features.csv")
label_df = pd.read_csv("labels.csv")

# Merge on image_path
data_df = pd.merge(clip_df, label_df, on="image_path")

# Shuffle and select 300k samples
data_df = data_df.sample(frac=1, random_state=42).reset_index(drop=True)
data_df = data_df.iloc[:300000]

# Extract features and labels
# Assume embedding columns are named emb_1 to emb_512
embedding_cols = [col for col in data_df.columns if col.startswith("emb_")]
X = data_df[embedding_cols].values.astype(np.float32)
y = data_df["label"].values.astype(np.float32)


✅ Step 2: Prepare PyTorch DataLoaders




# Convert to tensors
X_tensor = torch.tensor(X)
y_tensor = torch.tensor(y)

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42)

# Create loaders
train_dataset = torch.utils.data.TensorDataset(X_train, y_train)
test_dataset = torch.utils.data.TensorDataset(X_test, y_test)
train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=256, shuffle=True)
test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=256)



✅ Step 3: MLP

class MLPClassifier(nn.Module):
    def __init__(self, input_dim):
        super(MLPClassifier, self).__init__()
        self.model = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()
        )
    def forward(self, x):
        return self.model(x)

model = MLPClassifier(X.shape[1])
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)

✅ Step 4: Train

n_epochs = 10
for epoch in range(n_epochs):
    model.train()
    total_loss = 0
    for xb, yb in train_loader:
        optimizer.zero_grad()
        preds = model(xb).squeeze()
        loss = criterion(preds, yb)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss:.4f}")

✅ Step 5: Eval

model.eval()
all_preds = []
all_labels = []
with torch.no_grad():
    for xb, yb in test_loader:
        preds = model(xb).squeeze()
        all_preds.extend(preds.numpy())
        all_labels.extend(yb.numpy())

# Binarize predictions
preds_bin = [1 if p >= 0.5 else 0 for p in all_preds]
print(classification_report(all_labels, preds_bin))

